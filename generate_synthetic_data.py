#!/usr/bin/env python3
"""
Generate Synthetic Training Data using OpenAI

Use OpenAI to generate realistic furniture specifications.
This lets us create thousands of training samples cheaply.

Strategy:
1. Ask OpenAI to describe common UK furniture items
2. Get dimensions, weights, categories
3. Validate against catalog data
4. Add to training set

This is "data augmentation" - generating realistic synthetic data
to fill gaps in our training set.
"""

import os
import json
import uuid
from datetime import datetime
from pathlib import Path
from openai import OpenAI
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from app.models import TrainingDataset
from dotenv import load_dotenv
import time

load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


# Common UK furniture items to generate
FURNITURE_TEMPLATES = [
    # IKEA items not in catalog yet
    "IKEA PO√ÑNG Rocking chair",
    "IKEA EKTORP Corner sofa",
    "IKEA LISABO Dining table",
    "IKEA HEMNES TV bench",
    "IKEA STUVA Storage combination",
    "IKEA NORDLI Chest of 6 drawers",
    "IKEA BRIMNES Day-bed",
    "IKEA TARVA Bed frame double",

    # Wayfair UK popular items
    "Wayfair Zipcode Design Corner Sofa",
    "Wayfair Mercury Row Platform Bed King",
    "Wayfair Ophelia Co Velvet Armchair",
    "Wayfair Brayden Studio Extending Dining Table",
    "Wayfair Williston Forge Industrial Bookcase",

    # John Lewis popular items
    "John Lewis Partners Croft Large Sofa",
    "John Lewis Partners Wilton Bed Super King",
    "John Lewis Partners Coniston Office Desk",
    "John Lewis Partners Alpha Display Cabinet",
    "John Lewis Partners Montreal Bookcase",

    # Generic UK furniture
    "Traditional Oak Dining Table 6 seater",
    "Modern Fabric Corner Sofa L-shaped",
    "Wooden King Size Bed Frame with storage",
    "Glass Display Cabinet tall",
    "Leather Recliner Armchair",
    "Pine Chest of Drawers 5 drawer",
    "White Gloss TV Stand",
    "Metal and Wood Industrial Shelving Unit",
    "Velvet 2 Seater Sofa",
    "Marble Coffee Table round",
]


def generate_furniture_specs(furniture_name: str) -> dict:
    """Use OpenAI to generate realistic furniture specifications"""

    prompt = f"""You are a furniture measurement expert. For the furniture item: "{furniture_name}"

Provide realistic UK measurements and specifications in this EXACT JSON format:
{{
  "name": "{furniture_name}",
  "category": "choose one: sofa, armchair, bed, wardrobe, chest_of_drawers, bookcase, shelving, dining_table, coffee_table, side_table, desk, tv_stand, sideboard, other",
  "length_cm": <number>,
  "width_cm": <number>,
  "height_cm": <number>,
  "weight_kg": <number>,
  "is_bulky": <true or false>,
  "is_fragile": <true or false>,
  "typical_price_gbp": <number>,
  "materials": ["material1", "material2"],
  "description": "Brief description of the item"
}}

Use typical/average measurements for this type of furniture in the UK.
Only respond with the JSON, nothing else."""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",  # Cheaper model for bulk generation
            messages=[
                {"role": "system", "content": "You are a furniture specification expert. Always respond with valid JSON only."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=500
        )

        # Parse response
        content = response.choices[0].message.content.strip()

        # Remove markdown code blocks if present
        if content.startswith("```"):
            content = content.split("```")[1]
            if content.startswith("json"):
                content = content[4:]

        specs = json.loads(content)

        # Calculate CBM
        length = specs.get('length_cm', 0)
        width = specs.get('width_cm', 0)
        height = specs.get('height_cm', 0)

        if length and width and height:
            specs['cbm'] = round((length * width * height) / 1_000_000, 4)
        else:
            specs['cbm'] = None

        return specs

    except Exception as e:
        print(f"   ‚ùå Error generating specs for {furniture_name}: {e}")
        return None


def generate_synthetic_dataset(num_items: int = 30, save_to_db: bool = True):
    """Generate synthetic training data"""

    print("=" * 80)
    print("üé® GENERATING SYNTHETIC TRAINING DATA with OpenAI")
    print("=" * 80)

    print(f"\nüìù Generating specifications for {len(FURNITURE_TEMPLATES)} furniture items...")
    print("   Using GPT-4o-mini (cheap & fast)")

    generated_samples = []
    total_cost = 0

    for idx, furniture_name in enumerate(FURNITURE_TEMPLATES[:num_items], 1):
        print(f"\n[{idx}/{min(num_items, len(FURNITURE_TEMPLATES))}] Generating: {furniture_name}")

        specs = generate_furniture_specs(furniture_name)

        if specs:
            print(f"   ‚úÖ {specs['category']:20s} | {specs['length_cm']}√ó{specs['width_cm']}√ó{specs['height_cm']}cm | CBM: {specs.get('cbm', 0):.3f}")

            training_sample = {
                'source': 'synthetic_openai',
                'item_name': specs['name'],
                'item_category': specs['category'],
                'length_cm': specs['length_cm'],
                'width_cm': specs['width_cm'],
                'height_cm': specs['height_cm'],
                'cbm': specs.get('cbm'),
                'weight_kg': specs['weight_kg'],
                'is_bulky': specs['is_bulky'],
                'is_fragile': specs['is_fragile'],
                'materials': specs.get('materials', []),
                'description': specs.get('description', ''),
                'verified': True,  # Generated by OpenAI = trusted
                'confidence': 0.95,  # High confidence in OpenAI's furniture knowledge
                'teacher_model': 'gpt-4o-mini'
            }

            generated_samples.append(training_sample)

            # Estimate cost (GPT-4o-mini is ~$0.15/1M input tokens, $0.6/1M output)
            # Rough estimate: ~500 tokens per item
            total_cost += 0.0003  # ~$0.0003 per item

        # Rate limiting - be nice to OpenAI
        time.sleep(0.5)

    print(f"\nüí∞ Estimated cost: ${total_cost:.2f}")
    print(f"‚úÖ Generated {len(generated_samples)} synthetic furniture specifications")

    # Save to database
    if save_to_db and generated_samples:
        database_url = os.getenv("DATABASE_URL", "postgresql://primehaul@localhost/primehaul_local")
        engine = create_engine(database_url)
        Session = sessionmaker(bind=engine)
        session = Session()

        added = 0
        for sample in generated_samples:
            # Check if exists
            existing = session.query(TrainingDataset).filter(
                TrainingDataset.item_name == sample['item_name'],
                TrainingDataset.source_type == 'synthetic_openai'
            ).first()

            if not existing:
                entry = TrainingDataset(
                    id=uuid.uuid4(),
                    image_url=None,
                    image_hash=None,
                    item_name=sample['item_name'],
                    item_category=sample['item_category'],
                    length_cm=sample['length_cm'],
                    width_cm=sample['width_cm'],
                    height_cm=sample['height_cm'],
                    cbm=sample['cbm'],
                    weight_kg=sample['weight_kg'],
                    is_bulky=sample['is_bulky'],
                    is_fragile=sample['is_fragile'],
                    packing_requirement='none',
                    source_type='synthetic_openai',
                    source_id=None,
                    confidence_score=sample['confidence'],
                    verified=sample['verified'],
                    used_in_training=False
                )
                session.add(entry)
                added += 1

        session.commit()
        print(f"üíæ Added {added} samples to training_dataset table")
        session.close()

    # Export to JSON
    output_file = Path("training_data_cache") / f"synthetic_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    output_file.parent.mkdir(exist_ok=True)

    export_data = {
        'generated_at': datetime.now().isoformat(),
        'total_samples': len(generated_samples),
        'estimated_cost_usd': total_cost,
        'model_used': 'gpt-4o-mini',
        'samples': generated_samples
    }

    with open(output_file, 'w') as f:
        json.dump(export_data, f, indent=2)

    print(f"üìÑ Exported to {output_file}")

    return export_data


if __name__ == "__main__":
    data = generate_synthetic_dataset(num_items=30, save_to_db=True)

    print("\n" + "=" * 80)
    print("‚úÖ SYNTHETIC DATA GENERATION COMPLETE!")
    print("=" * 80)
    print(f"\nGenerated {data['total_samples']} new training samples")
    print(f"Cost: ${data['estimated_cost_usd']:.2f} (vs $0 to collect them manually)")
    print("\nThese are now in our training_dataset table!")
    print("\nNext: Run train_furniture_model.py to train on ALL data sources:")
    print("  - Catalog items (49)")
    print("  - OpenAI detections (extracted)")
    print("  - Synthetic data (30)")
    print("  - Admin feedback (as it comes)")
